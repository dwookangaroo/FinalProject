{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  파일 길이 :  218\n",
      "a  :  ./img/a\\HF010011_0000_0011.jpg\n",
      "b  파일 길이 :  280\n",
      "b  :  ./img/b\\HF010012_0000_0001.jpg\n",
      "c  파일 길이 :  390\n",
      "c  :  ./img/c\\HF010014_0000_0002.jpg\n",
      "ok 888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT-R45\\anaconda3\\envs\\project_env\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "caltech_dir = \"./img\"\n",
    "categories = ['a', 'b', 'c']\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"./img/image_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666, 64, 64, 3)\n",
      "666\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\n",
    "X_train, X_test, y_train, y_test = np.load('./img/image_data.npy')\n",
    "np.load = np_load_old\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['a', 'b', 'c']\n",
    "nb_classes = len(categories)\n",
    "\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "    \n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,214,723\n",
      "Trainable params: 4,214,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 1.6045 - accuracy: 0.5631 - val_loss: 0.8922 - val_accuracy: 0.7117\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 0.4621 - accuracy: 0.8258 - val_loss: 0.3100 - val_accuracy: 0.8649\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 0.2384 - accuracy: 0.9249 - val_loss: 0.2026 - val_accuracy: 0.9279\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 0.1422 - accuracy: 0.9565 - val_loss: 0.1665 - val_accuracy: 0.9459\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 0.0899 - accuracy: 0.9670 - val_loss: 0.1165 - val_accuracy: 0.9730\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 0.0748 - accuracy: 0.9685 - val_loss: 0.0784 - val_accuracy: 0.9775\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 0.0606 - accuracy: 0.9745 - val_loss: 0.0571 - val_accuracy: 0.9865\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 0.0664 - accuracy: 0.9760 - val_loss: 0.1061 - val_accuracy: 0.9685\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 0.0376 - accuracy: 0.9880 - val_loss: 0.0548 - val_accuracy: 0.9865\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 0.0155 - accuracy: 0.9985 - val_loss: 0.0493 - val_accuracy: 0.9865\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.0449 - val_accuracy: 0.9865\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 0.0233 - accuracy: 0.9940 - val_loss: 0.0448 - val_accuracy: 0.9820\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0797 - accuracy: 0.9700 - val_loss: 0.1642 - val_accuracy: 0.9279\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 0.0525 - accuracy: 0.9805 - val_loss: 0.0667 - val_accuracy: 0.9775\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 0.0183 - accuracy: 0.9955 - val_loss: 0.0560 - val_accuracy: 0.9865\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.0434 - val_accuracy: 0.9910\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0378 - val_accuracy: 0.9910\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9910\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9910\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9910\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9865\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 0.0402 - val_accuracy: 0.9865\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0352 - val_accuracy: 0.9910\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9910\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 8.9649e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9910\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 9.4544e-04 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9910\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 9.2619e-04 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9910\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3967e-04 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9865\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 3.7130e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9865\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 4.3749e-04 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9865\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 3.1028e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9910\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 3.5986e-04 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9910\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 3.5366e-04 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9865\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 2.5664e-04 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9865\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 2.2300e-04 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9910\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 1.5537e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9910\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 1.9119e-04 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9910\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 1.7242e-04 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9910\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 2.5584e-04 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9910\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 2.9773e-04 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9910\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 2.8468e-04 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9910\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 1.8314e-04 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9865\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 1.6483e-04 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9910\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 1.0069e-04 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9910\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 2.2106e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9910\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 1.6337e-04 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9910\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 2.8977e-04 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9910\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 1.3505e-04 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9910\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 9.7772e-05 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9910\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 5.1141e-04 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0371 - accuracy: 0.9910\n",
      "정확도 : 0.9910\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_sample.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000 0.000 0.000]\n",
      "0\n",
      "해당 경릉.jpg이미지는 a로 추정됩니다.\n",
      "[0.000 0.000 1.000]\n",
      "2\n",
      "해당 다운로드 (1).jpg이미지는 c로 추정됩니다.\n",
      "[0.000 0.000 1.000]\n",
      "2\n",
      "해당 다운로드.jpg이미지는 c로 추정됩니다.\n",
      "[1.000 0.000 0.000]\n",
      "0\n",
      "해당 얘릉.jpg이미지는 a로 추정됩니다.\n",
      "[0.000 1.000 0.000]\n",
      "1\n",
      "해당 예릉1.jpg이미지는 b으로 추정됩니다.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "caltech_dir = \"./test\"\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)\n",
    "model = load_model('./model_sample.h5')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "\n",
    "#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
    "for i in prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    print(i)\n",
    "    print(pre_ans)\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"a\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"b\"\n",
    "    elif pre_ans == 2: pre_ans_str = \"c\"\n",
    "    else: pre_ans_str = \"게\"\n",
    "    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "    if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    cnt += 1\n",
    "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
    "    # 이걸 한 것은 _4.py에."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
